# -*- coding: utf-8 -*-
"""Finalclassifierwith3Attribute.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vsRq0vBb_lmABIzov2E4wlx0uOPFt824
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install numpy pandas

import time

# Record the start time
start_time = time.time()

import numpy as np
import pandas as pd
#import seaborn as sns
#import matplotlib.pyplot as plt
#Python 3.11.2

# Commented out IPython magic to ensure Python compatibility.
# %pip install tensorflow

# Commented out IPython magic to ensure Python compatibility.
# %pip install opencv-python

#from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
import keras
from keras.preprocessing.image import ImageDataGenerator
from keras import applications
from keras.models import Sequential, load_model
from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Dropout
from keras.preprocessing import image

import cv2

import warnings
warnings.filterwarnings('ignore')

import os



"""<h1>Dataset</h1>"""

from google.colab import drive
drive.mount("/content/drive")

# datasets
#labels = pd.read_csv("./labels.csv")
labels = pd.read_csv("/content/drive/MyDrive/PhD Work/InceptionResNetV2 architecture 3Attribute/KaranjNeemDataset (1).csv")
#sample = pd.read_csv('/content/drive/My Drive/dog/sample_submission.csv')

# folders paths
train_path = "/content/drive/MyDrive/PhD Work/InceptionResNetV2 architecture 3Attribute/Allinone3Attribute"
#test_path = "./test"

#import os.listdir() to os.pathjoin to the files, import files , print name of files, label files
#loading images dataset of documents : labels of documents:img,doc , train dataset:img of doc, test dataset:img of doc

labels.head()

labels = labels.sample(frac=1)

# invoicebank invoice
# insurance   car
# insurance   bike

labels["id"] = labels["image"]

#what is validation split
# Data agumentation and pre-processing using tensorflow
gen = ImageDataGenerator(
                  rescale=1./255.,
                  horizontal_flip = True,
                  validation_split=0.2 # training: 80% data, validation: 20% data
                 )

train_generator = gen.flow_from_dataframe(
    labels, # dataframe
    directory = train_path, # images data path / folder in which images are there
    x_col = 'image',
    y_col = 'type',
    subset="training",
    color_mode="rgb",
    target_size = (331,331), # image height , image width
    class_mode="categorical",
    batch_size=32,
    shuffle=True,
    seed=42,
)


validation_generator = gen.flow_from_dataframe(
    labels, # dataframe
    directory = train_path, # images data path / folder in which images are there
    x_col = 'image',
    y_col = 'type',
    subset="validation",
    color_mode="rgb",
    target_size = (331,331), # image height , image width
    class_mode="categorical",
    batch_size=32,
    shuffle=True,
    seed=42,
)

import sys
import PIL
from PIL import Image

x,y = next(train_generator)
x.shape # input shape of one record is (331,331,3) , 32: is the batch size

#x.shape , (32,331,331,3)

y.shape #y.shape (32,3)

y[3]

# Commented out IPython magic to ensure Python compatibility.
# %pip install matplotlib

import matplotlib.pyplot as plt



a = train_generator.class_indices
class_names = list(a.keys())  # storing class/breed names in a list
# a is dictionary with each breed assigned number , a.keys is dictionary of only keys, list(a.keys()) making dictionary to list

def plot_images(img, labels):
    plt.figure(figsize=[15, 10])
    for i in range(25):
        plt.subplot(5, 5, i+1)
        plt.imshow(img[i])
        plt.title(class_names[np.argmax(labels[i])])
        plt.axis('off')

plot_images(x,y)

class_names

a.keys()

"""<h1>Model Build</h1>"""

# load the InceptionResNetV2 architecture with imagenet weights as base
base_model = tf.keras.applications.InceptionResNetV2(
                     include_top=False,
                     weights='imagenet',
                     input_shape=(331,331,3)
                     )

base_model.trainable=False
# For freezing the layer we make use of layer.trainable = False
# means that its internal state will not change during training.
# model's trainable weights will not be updated during fit(),
# and also its state updates will not run.

model = tf.keras.Sequential([
        base_model,
        tf.keras.layers.BatchNormalization(renorm=True),
        tf.keras.layers.GlobalAveragePooling2D(),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dense(256, activation='relu'),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(6, activation='softmax')
    ])

model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])
# categorical cross entropy is taken since its used as a loss function for
# multi-class classification problems where there are two or more output labels.
# using Adam optimizer for better performance
# other optimizers such as sgd can also be used depending upon the model

model.summary()

early = tf.keras.callbacks.EarlyStopping( patience=10,
                                          min_delta=0.001,
                                          restore_best_weights=True)
# early stopping call back

"""<h1>Train Model</h1>"""

print(train_generator.batch_size)
train_generator.n//train_generator.batch_size

print(validation_generator.batch_size)
validation_generator.n//validation_generator.batch_size

batch_size=32
STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size
STEP_SIZE_VALID = validation_generator.n//validation_generator.batch_size

# fit model
history = model.fit(train_generator,
                    steps_per_epoch=STEP_SIZE_TRAIN,
                    validation_data=validation_generator,
                    validation_steps=STEP_SIZE_VALID,
                    epochs=5,
                    callbacks=[early])

"""<h1>Save Model</h1>"""

model.save("/content/drive/MyDrive/PhD Work/InceptionResNetV2 architecture/3Attribute3AttributePlantModel.h5")

"""# @title Default title text
from keras.models import load_model
import os
model.save(os.path.join('models','/content/drive/MyDrive/PhD Work/InceptionResNetV2 architecture/3Attribute3AttributePlantModel.h5')) #model directory
new_model = load_model('/content/drive/MyDrive/PhD Work/InceptionResNetV2 architecture/3Attribute3AttributePlantModel.h5')
#yhatnew = new_model.predict(np.expand_dims(resize/255,0))

<h1>Model Performance</h1>
"""

# store results
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']


# plot results
# accuracy
plt.figure(figsize=(10, 16))
plt.rcParams['figure.figsize'] = [16, 9]
plt.rcParams['font.size'] = 14
plt.rcParams['axes.grid'] = True
plt.rcParams['figure.facecolor'] = 'white'
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.title(f'\nTraining and Validation Accuracy. \nTrain Accuracy:{str(acc[-1])}\nValidation Accuracy: {str(val_acc[-1])}')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.title(f'Training and Validation Loss. \nTrain Loss:{str(loss[-1])}\nValidation Loss: {str(val_loss[-1])}')
plt.xlabel('epoch')
plt.tight_layout(pad=3.0)
plt.show()

accuracy_score = model.evaluate(validation_generator)
print(accuracy_score)
print("Accuracy: {:.4f}%".format(accuracy_score[1] * 100))

print("Loss: ",accuracy_score[0])

"""<h1>Test Model</h1>"""

test_img_path = "/content/drive/MyDrive/PhD Work/InceptionResNetV2 architecture 3Attribute/Allinone3Attribute/1456.jpg"
 #test_img_path = "./home/Documents/Documents/Project/Invoice Insurance Images/train/1.jpg"
img = cv2.imread(test_img_path)
plt.imshow(img)
resized_img = cv2.resize(img, (331, 331)).reshape(-1, 331, 331, 3)/255

#plt.figure(figsize=(6,6))
#plt.title("TEST IMAGE")
#plt.imshow(resized_img[0])
prediction = model.predict(resized_img)
print(class_names[np.argmax(prediction)])

"""## **Now we list the medicinal properties of the plant detected**"""

class_prediction=class_names[np.argmax(prediction)]

if class_prediction == 'Karanj Trunk' or class_prediction == 'Karanj Leaf' or class_prediction == 'Karanj Seed':
    print('Karanj Popularly known as Indian Beech in outside India is a medicinal herb used mainly for skin disorders. Karanja oil is applied to the skin to manage boils, rashes, and eczema as well as heal wounds due to its antimicrobial properties. The oil can also be useful in arthritis due to its anti-inflammatory activities.')

if class_prediction == 'Neem Trunk' or class_prediction == 'Neem Leaf' or class_prediction == 'Neem Seed':
    print('Neem is a versatile medicinal tree. Neem oil and neem leaves are used for various medicinal purposes. It has anti-inflammatory, antifungal, and antibacterial properties, making it beneficial for skin care, hair care, and managing various health conditions.')

if class_prediction == 'Peeple Trunk' or class_prediction == 'Peeple Leaf' or class_prediction == 'Peeple Seed':
    print('Peepal: The bark of the Peeple tree, rich in vitamin K, is an effective complexion corrector and preserver. It also helps in various ailments such as Strengthening blood capillaries, minimising inflammation, Healing skin bruises faster, increasing skin resilience, treating pigmentation issues, wrinkles, dark circles, lightening surgery marks, scars, and stretch marks.')

end_time = time.time()

# Calculate the elapsed time
elapsed_time = end_time - start_time

print(f"Time taken: {elapsed_time:.2f} seconds")

Time_in_Minute = elapsed_time / 60
print(f"Time taken: {Time_in_Minute:.2f} minutes")